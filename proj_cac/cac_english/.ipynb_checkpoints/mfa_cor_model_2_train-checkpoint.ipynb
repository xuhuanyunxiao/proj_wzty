{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保监会 相关性模型 2 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-09T09:19:46.975968Z",
     "start_time": "2018-08-09T09:19:46.932966Z"
    }
   },
   "outputs": [],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一版模型读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:42:59.136881Z",
     "start_time": "2018-07-19T02:42:53.723420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型\n",
    "# from sklearn.externals import joblib\n",
    "# pipeline_old = joblib.load( \"model/circ_cor_0625.pkl.z\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-09T09:20:17.322704Z",
     "start_time": "2018-08-09T09:20:17.249700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5776\n",
      "5776\n"
     ]
    }
   ],
   "source": [
    "folder = '20180808'\n",
    "\n",
    "# 相关数据\n",
    "corpus_cor = []\n",
    "label_cor = []\n",
    "\n",
    "filename = 'data/{0}/corpus_pre_cor_0809.txt'.format(folder)\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    corpus_cor.append(f)\n",
    "    label_cor.append(1)\n",
    "fid.close()\n",
    "print(len(corpus_cor))\n",
    "print(len(label_cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:43:04.226560Z",
     "start_time": "2018-07-19T02:43:02.948487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8949\n",
      "8949\n"
     ]
    }
   ],
   "source": [
    "# 不相关数据\n",
    "corpus_uncor = []\n",
    "label_uncor = []\n",
    "\n",
    "filename = 'data/{0}/corpus_pre_uncor_0809.txt'.format(folder)\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    corpus_uncor.append(f)\n",
    "    label_uncor.append(0)\n",
    "fid.close()\n",
    "print(len(corpus_uncor))\n",
    "print(len(label_uncor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:43:04.255561Z",
     "start_time": "2018-07-19T02:43:04.231560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'月 日 闽侯 万佛寺 祈福 永泰 赏 梅花 旗山 森林 温泉 度假村 品 永泰 葱饼 特价 一日游 特价 特价 特价 元 人 含 车费 原价 元 温泉 特惠 门票 活动 时间 年 月 日 星期天 集合时间 上午 集中 准时 出发 超时 不侯 集合地点 福州 工业 路 万象 城 麦当劳 东側 中央 第五 街 下面 上车 集中 指示 相片 活动 性质 自愿 参加 量力而行 保险 自购 风险 自负 户外 风险 参加 需谨慎 购买 保险 网址 https 活动 类别 感受 户外 生活 祈福 赏花 摄影 泡温泉 风景 指数 活动 强度 休闲游 亲子 游 线路 地点 福州 闽侯 永泰 福州 活动 费用 元 人 往返 车费 原 元 温泉 特惠 门票 米 以下 小孩 车费 元 人 景区 特价 活动 任何 证件 均 不再 优惠 上车 缴费 午餐 自理 自带 干粮 镇上 自行 午餐 按照 报名 先后顺序 安排 车上 座位 按车 均分 顺序 诚信 报名 报名者 如 活动 前 小时 内 退出 应 自觉 缴纳 本次 活动 车费 代 报名者 负责 补交 找 其他人 替补 请 大家 共同 遵守 报名 方式 请 参加者 发短信 报名 发短信 格式 日 旗山 温泉 网名 名字 qq 网名 参加 人数 接收 短信 手机 活动 行程 安排 早上 万象 城 发车 永泰 葛岭 赏花 和品 永泰 葱饼 上车 前往 游 旗山 万福 寺 镇上 自行 午餐 驱车 旗山 温泉 度假村 泡温泉 适时 返回 福州 线路 介绍 福州 城 四周 青山 耸翠 碧水 环绕 西郊 之旗 山群峰 旖旎 奇岩 幽壑 飞泉 流涧 景色 佳绝 鼓山 隔江 相峙 素有 左旗 右鼓 八闽 二绝 之誉 自古 道 天下 名山 僧 占 多 名山 古刹 相得益彰 也 唐代 以后 峰回 水曲 洞天福地 之中 旗山 曾 九庵 十八 寺 错落 其间 而 今天 要说 中国 占地 规模 最大 佛教 寺院 万佛寺 位于 旗山 之麓 万顷 石松 围 佛寺 一江 闽水绕 旗山 寺 前 对联 万佛 万玉 也 寺 中之佛 佛佛 皆 玉雕 而成 如今 海内外 佛教 信徒 朝拜 圣地 也 成为 东南 旅游 重要 景观 永泰 成片 梅林 中 一朵朵 白 梅花 密密麻麻 点缀 枝丫 间 远远 看去 犹如 刚下 一场 冬雪 整座 山 变成 白色 一株株 梅树 挺直 腰杆 一颗颗 花蕾 争先 开放 一时间 满山 银装素裹 满树 梅花 傲立 枝头 不需 走进 一阵 清香 便 迎面 飘来 让 人 不知不觉 陶醉 王安石 诗境 中 美丽 来自 自然 健康 来自 温泉 旗山 森林 温泉 具备 保健 美容 护肤 疗养 功效 依山 而 建 温泉 中心 座 独具 风味 温泉 汤池 间 独享 尊贵 温泉 汤屋 分为 动感 泡池区 养生 泡池区 生态 泡池区 三大泡 池区 包含 鱼疗 池 红茶 泉 红 酒泉 牛奶 泉 人参 泉 多种 特色 温泉 背上 行囊 一起 去 神游 报名 须知 年 须 周岁 周岁 小孩 需 父母 全程 陪同 高血压 心脏病 性格 孤僻 以逸待劳 斤斤计较 不能 同甘共苦 俱乐部 视同 旅行社 人 参加 谢绝 参加 免责 声明 参加者 均 视为 具有 完全 民事行为 能力 人 自行 承担 产生 后果 负 完全 责任 本 俱乐部 活动 以 盈利 为 目的 属 结伴同游 性质 自愿 参加 参加者 已 认识 到 户外活动 风险 自助 活动 风险 自负 一切 意外 俱乐部 领队 无关 组织者 领队 均 承担 任何 相应 法律责任 经济 赔偿 责任 参加者 放弃 对 同行 组织者 领队 队友 索赔权 参加者 必须 个人 自行 购买 相关 意外 伤害 保险 后 参加 不是 旅行社 结伴同游 没有 保姆式 服务 一切 后勤 事物 需要 队员 协作 完成 可能 遭遇 迷路 堵车 坏车 一系列 无法 预料 情况 会 抱怨 请 三思而后行 特此 声明 活动 开始 后 本 声明 将 自动 生效 并 表明 接受 本 声明 否则 请 活动 开始 前 退出 本次 活动 若因 天气 不可 抗拒 外力 影响 低于 成行 人数 将 对 线路 调整 取消 请 出发 前 及时 本 网站 公告 途中 一些 不可 预计 因素 引起 计划 变更 民主 原则 最终 以 领队 意见 为准 参加者 均 视为 同意 以上 条款 个人 装备 建议 穿 软底 防滑 鞋 长袖 宽松 衣 裤 遮阳帽 毛巾 饮用水 雨具 报名 截止 日期 限 人数 报满 为止 请 参加者 马上发 报名 短信 自即日起 开始 名 报名 电话 仙游 手机号 微信 同号 网址 http 组织 活动 q q 群号 微信 公众 号 zgfj 上车 集中 地点 图 报名 确认 名 诚信 报名 占 坑者 活动 前 小时 内 退出 应 缴纳 本次 活动 车费 代 报名者 负责 补交 请 大家 共同 遵守 请 参加 人员 活动 前一天 晚上 之后 登陆 网站 再次 核对 名单 以 报名 先后顺序 安排 车辆 座位 按车 均分 想 去 抓紧 以 确认 报名 为准 位满 截止 如需 调整 座位 请 大家 自行 友好 协商 确认 名单 第一部 车 领队 小霞 人 计 限 提示 报名 方式 请 参加者 发短信 报名 发短信 格式 日 旗山 温泉 网名 名字 qq 网名 参加 人数 接收 短信 手机 报名 以 发短信 未 发短信 确认 朋友 请速发 确认 短信 谢谢合作 组织 活动 咨询 q q 群号 微信 公众 号 zgfj 保险 购置 方法 活动 性质 自愿 参加 结伴 而行 保险 自购 风险 自负 户外 风险 参加 需谨慎 为了 家人 安全 保障 提醒 参加 户外活动 购买 保险 请 参加者 网银 微信 支付 信用卡 支付宝 自行 购买 户外活动 保险 如需 协助 代购 保险 驴友 报名 时 将 网名 姓名 身份证 号码 手机号码 缺一不可 传至 仙游 手机 需加 元 人 保险 代购 款 本次 活动 选择 保险产品 购买 网址 https 现代 保险 齐乐游 计划 C 投保 须知 投保 前 请 仔细阅读 产品 条款 费率 表 客户 告知 书 保单 样本 免除 责任 保障 责任 犹豫 期 费用 扣除 退保 保险单 现金 价值 投保人 被保险人 义务 内容 详见 产品 条款 请 务必 仔细阅读 产品 条款 电子 保单 特别 约定 投保 须知 所有 保险责任 条款 均 以 现代财产保险 中国 有限公司 签发 正式 保险合同 相应 条款 为准 本 计划 承保 年 为 周岁 以 保单生效 时 周岁 年 为准 周岁 被保险人 其 涉及 意外 身故 残疾 保障 公共 交通工具 意外 保障 急性病 身故 保障 自驾车 意外 身故 残疾 保险金额 为 上表 载 金额 一半 保险费 维持 不变 周岁 以上 被保险人 因 保险 事故 造成 意外 急性病 医疗 保险公司 扣除 元免 赔后 赔付 按 中国保监会 规定 周岁 以下 未成年人 累计 身故 保险金额 不得 超过 人民币 万元 周岁 未成年人 累计 身故 保险金额 不得 超过 人民币 万元 若 未成年 被保险人 保险金额 超过 上述 规定 以 上述 规定 保险金额 为限 同一 保险 期间 每位 被保险人 投保 同一 产品 包括 同一 产品 同一 计划 不同 计划 限 投保 一份 如果 投保 多份 同一 计划 以 最先 投保 保单 为 有效 其余部分 视为 无效 保险费 将 无息 退还 如果 投保 多份 不同 计划 以 意外 伤害 保额 最高 保单 为 有效 其余部分 视为 无效 保险费 将 无息 退还 本 保险产品 单次 承保 最长 期间 为 天 本 保险 仅 承保 中华人民共和国 大陆 地区 境内 含 香港 澳门 台湾 地区 外籍人士 购买 本 产品 符合 投保 规则 即可 无 其它 特殊要求 本 产品 承保 被保险人 从事 潜水 滑水 滑雪 滑冰 驾驶 乘坐 滑翔翼 滑翔伞 跳伞 攀岩 运动 探险 活动 如 江河 漂流 武术比赛 摔跤 比赛 柔道 空手道 跆拳道 马术 拳击 特技表演 驾驶 卡丁车 赛马 赛车 各种 车辆 表演 蹦极 溯溪 高风险 运动 承保 旅行 期间 休闲 旅游 景区 内 滑雪 漂流 骑马 运动 业余 跑步 远足 徒步 登山运动 海拔高度 米 以下 定向 运动 拓展 活动 场地 趣味 活动 自行车 运动 山地 自行车 越野 场地 越野 轮滑 自驾车 旅行 游泳 低 风险 运动 前述 仅限 体验式 活动 包含 专业 性质 训练 运动 本 产品 指定 医院 为 符合 条款 要求 医院 除了 北京 平谷区 所有 医院 请 注意 北京市 平谷区 所有 医院 就医 均 给予 理赔 被保险人 故意 做出 危险性 行为 而 导致 意外 伤害事故 保险公司 承担 保险责任 危险性 行为 包括 但 限于 听从 导游 领队 教练 现场 安全 人员 要求 劝阻 违反 景区 当地 警示 禁令 标示 违规 进入 国家 当地政府 明令禁止 线路 地区 投保 表格 下载 人 国内 旅游 团购 模板 xls 福州 旗山 万佛寺 原为 旗 山石 松寺 始建 宋 大中祥符 三年 公元 年 初名 灵凤寺 绍兴 十年 公元 年 寺僧 天石于 寺 旁 种植 爪 松 长成 易名 为 石松 寺 明成化 万历 年间 两次 修建 颇具规模 曾 福州 佛教 圣地 年 政府 批准 重建 石松 寺 并 更名 为 旗山 万佛寺 雪峰 寺 方丈 释广霖 构思 提议 将 该寺 建为 全国 最大 寺院 藏 万尊 白瓷 佛 立寺 名曰 旗山 万佛寺 梅花香 自苦寒 来 最近 几天 永泰 梅树 已 进入 盛花期 正是 观赏 最佳时期 花朵 成片 成片 绽放 蔚为壮观 一朵朵 白 梅花 密密麻麻 点缀 枝丫 间 远远 看去 犹如 刚下 一场 冬雪 整座 山 变成 白色 一株株 梅树 挺直 腰杆 一颗颗 花蕾 争先 开放 一时间 满山 银装素裹 满树 梅花 傲立 枝头 不需 走进 一阵 清香 便 迎面 飘来 让 人 不知不觉 陶醉 王安石 诗境 中 山间 小道 而 上 观赏 到 成片 盛开 如雪 腊梅 林 近距离 欣赏 梅花 花姿 风韵 将 陶醉 遥知 不是 雪 唯有 暗香 来 梅林 中 此时 梅花 姿态 各异 俯 或仰 或侧 卧 依 梅花 树皮 漆黑 而多糙 纹 其 虬枝 苍劲 嶙峋 风韵 洒落 一种 饱经沧桑 威武不屈 阳刚之美 梅花 枝条 明晰 色彩 和谐 或曲 如游 披靡 而 下 多变 而 规律 呈现出 一种 很强 力度 刚硬 线条美 身处 梅林 中 梅花 缤纷 梅影 阵阵 徜徉 花丛 之中 聊天 也好 发呆 也好 赏花 也好 留影 也好 随心 而 为 微风 阵阵 略过 梅林 犹如 浸身 香海 通体 蕴香 冬日 梅花 树 下 不时 还 观得 几瓣 梅花 随风飘 落 静静 散落 身边 轻轻 划过 指尖 惬意 也 爱人 一起 漫步 梅林 之间 感受 枝头 点点 香雪 冬日 里 倾诉 绵绵 情话 也 带 孩子 梅林 中 享受 冬日 暖阳 呼吸 伴着 阵阵 花香 空气 还 将 孩子 天真 顽皮 一举一动 捕入 镜头 为 成长 留下 美好 回忆 下午 再 一起 去 泡个 舒适 温泉 冬日 阳光 下 享受 泡温泉 感觉 最 美妙 享受 温泉 中 含有 丰富 矿物质 不仅 对 多种 疾病 均 疗效 作用 而且 保健 美容 护肤 疗养 功效 永泰 葱 饼 福建 永泰 传统 名点 香脆 可口 让 人 回味无穷 刚 出炉 葱 饼 片刻 之后 酥脆 无比 咬 一小 口 葱香 肉香 芝麻 香 唇 留香 jpg KB jpg KB jpg KB \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_uncor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:43:04.779591Z",
     "start_time": "2018-07-19T02:43:04.274562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 13554\n",
      "训练集-各类数量： Counter({0: 8087, 1: 5467})\n",
      "测试集： 1506\n",
      "测试集-各类数量： Counter({0: 862, 1: 644})\n"
     ]
    }
   ],
   "source": [
    "# 未加入系统中噪音\n",
    "corpus = corpus_cor + corpus_uncor\n",
    "label = label_cor + label_uncor\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, label, test_size=0.1, random_state=42)\n",
    "print('训练集：',len(y_train))\n",
    "print('训练集-各类数量：',Counter(y_train))\n",
    "print('测试集：',len(y_test))\n",
    "print('测试集-各类数量：',Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:47:51.997047Z",
     "start_time": "2018-07-19T02:47:51.964045Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ea83e23c7ca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m'chi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         ])),\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m'len_stats'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStatsFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     ]))\n",
      "\u001b[1;32mD:\\software\\conda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\conda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# validate names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:51:05.847574Z",
     "start_time": "2018-07-19T02:48:05.038706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=2))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:04.027707Z",
     "start_time": "2018-07-03T06:52:51.087583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536668142245831\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:55:29.159675Z",
     "start_time": "2018-07-19T02:55:26.997375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8911022576361222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       862\n",
      "          1       0.92      0.82      0.87       644\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[813  49]\n",
      " [115 529]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:06.947443Z",
     "start_time": "2018-07-03T06:53:05.381974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8652058432934927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88       862\n",
      "          1       0.85      0.84      0.84       644\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[764  98]\n",
      " [105 539]]\n"
     ]
    }
   ],
   "source": [
    "# 上一版模型 \n",
    "y_pred_class = pipeline_old.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:57:03.671303Z",
     "start_time": "2018-07-19T02:57:03.316283Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:02:02.771607Z",
     "start_time": "2018-07-19T04:01:47.065334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13554, 20005)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features = FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])\n",
    "\n",
    "X_features = combined_features.fit(X_train, y_train).transform(X_train)\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:03:29.273139Z",
     "start_time": "2018-07-19T04:03:29.248137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svc = Pipeline([('features', combined_features),('classifier', SVC())])\n",
    "\n",
    "pipeline_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:03:33.644548Z",
     "start_time": "2018-07-19T04:03:33.626547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': [1, 10, 100, 1000],\n",
       " 'classifier__kernel': ['rbf', 'linear'],\n",
       " 'features__tf_idf_chi__k': [5000, 20000, 40000]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(features__tf_idf_chi__k=[5000, 20000, 40000],\n",
    "                  classifier__kernel = ['rbf','linear'],\n",
    "                  classifier__C = [1, 10, 100, 1000])\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-19T04:03:36.576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(pipeline_svc, param_grid, cv=5,n_jobs = -1, \n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:30:14.097903Z",
     "start_time": "2018-07-19T03:30:14.066703Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d434638f22f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:51:12.095774Z",
     "start_time": "2018-06-13T09:51:11.751754Z"
    },
    "collapsed": true
   },
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.531160Z",
     "start_time": "2018-07-03T06:53:06.953443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/circ_cor_0703.pkl.z']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/circ_cor_0703.pkl.z\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.560161Z",
     "start_time": "2018-07-03T06:53:13.537160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
